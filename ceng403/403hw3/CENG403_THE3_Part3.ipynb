{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X4X2hmaEmip"
      },
      "source": [
        "# CENG403 - Spring 2024 - THE3\n",
        "# Task 3: Finetune ResNet\n",
        "\n",
        "In this task, we will practice transfer learning by adapting and finetuning ResNet18 (pretrained on ImageNet) for CIFAR10.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KyHtEWkOuZW"
      },
      "source": [
        "## 3.1 Download and Test Pretrained ResNet18\n",
        "\n",
        "We have talked about ResNet in detail in the lectures. We will take Pytorch's ResNet18 model (https://pytorch.org/hub/pytorch_vision_resnet/), which was trained on ImageNet, and adapt & finetune it for CIFAR10.\n",
        "\n",
        "Here are a couple of critical information about ResNet18's input (from Pytorch docs):\n",
        "\n",
        "<i>\"All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].\"</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWxyCVI_OTdi"
      },
      "source": [
        "### 3.1.1 Download ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Thanks to Pytorch datasets, this is very easy:\n",
        "\n",
        "OrigResNet18 = None\n",
        "###########################################################\n",
        "# @TODO: Look at PyTorch's documentation for downloading  #\n",
        "# and loading a pretrained ResNet18 model.                #\n",
        "#                                                         #\n",
        "# Hint: This should be a single function call.            #\n",
        "###########################################################\n",
        "\n",
        "\n",
        "###########################################################\n",
        "#                         END OF YOUR CODE                #\n",
        "###########################################################\n",
        "print(OrigResNet18)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K1Qp-TV7Npz",
        "outputId": "ad853b42-62e6-4778-f50e-5d1ae9b083f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bDj9IQRL7ms"
      },
      "source": [
        "### 3.1.2 Get ImageNet Labels\n",
        "\n",
        "Before we finetune ResNet18, let us see what it predicts on CIFAR10. To be able to do so, we will require the list of ImageNet labels."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download ImageNet labels\n",
        "!wget -nc https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
        "\n",
        "# Read the categories\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]"
      ],
      "metadata": {
        "id": "EnCnO18N7Scy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk6K0jC_OZs0"
      },
      "source": [
        "### 3.1.3 Load CIFAR10\n",
        "\n",
        "As we mentioned above, ResNet18 expects images with resolution 224x224 and normalized with a mean & std. Therefore, while loading CIFAR10, we will apply certain transformations to handle these requirements. (Note that this cell is slightly different than 2.3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "\n",
        "TF = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=TF)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=TF)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "CIFAR10_classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "5HRQY0yM7oTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUxUQKZSO3q2"
      },
      "source": [
        "### 3.1.4 Apply Pre-trained ResNet18 on CIFAR10\n",
        "\n",
        "Let us look at what ResNet18 predicts on a batch of CIFAR10. For a set of samples, we will visualize the images and look at ResNet18's top predictions."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Get scores for classes on the batch\n",
        "with torch.no_grad():\n",
        "    output = OrigResNet18(images)\n",
        "\n",
        "# Convert them to probabilities (shape: batch_size x 1000)\n",
        "probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "\n",
        "# Show results on a 2x2 grid\n",
        "S=2\n",
        "for i in range(S):\n",
        "  for j in range(S):\n",
        "    X = images[i*S+j]\n",
        "    X = np.transpose((X.numpy()/2+0.5), (1, 2, 0))\n",
        "    top1_prob, top1_catid = torch.topk(probabilities[i*S+j], 1)\n",
        "    title = \"{} p:{:1.2f}\".format(categories[top1_catid], top1_prob.item())\n",
        "\n",
        "    plt.subplot(S, S, i*S+j+1)\n",
        "    plt.imshow(X)\n",
        "    plt.axis('off')\n",
        "    plt.title(title)\n",
        "    plt.subplots_adjust(hspace = 0.5)\n"
      ],
      "metadata": {
        "id": "KbITob-576pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the predictions are way off and we will hopefully get better results with some finetuning."
      ],
      "metadata": {
        "id": "UrHglujl79zy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV9omiSefxOU"
      },
      "source": [
        "## 3.2 Adapt ResNet18 for CIFAR10\n",
        "\n",
        "We will \"freeze\" the parameters of ResNet18 and replace the last layer of ResNet18 with a new layer which we will finetune."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy ResNet18\n",
        "import copy\n",
        "NewResNet18 = copy.deepcopy(OrigResNet18)"
      ],
      "metadata": {
        "id": "sXcniP0b8-Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTt3F-EHI1_9"
      },
      "source": [
        "### 3.2.1 Freeze Parameters of ResNet18\n",
        "\n",
        "We \"freeze\" a parameter by setting its `requires_grad` member variable to `False`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################\n",
        "# @TODO: Go over the parameters of NewResNet18 and set    #\n",
        "# requires_grad for all parameters to False.              #\n",
        "#                                                         #\n",
        "# Hint: Check parameters() member function of NewResNet18.#\n",
        "###########################################################\n",
        "\n",
        "\n",
        "###########################################################\n",
        "#                         END OF YOUR CODE                #\n",
        "###########################################################"
      ],
      "metadata": {
        "id": "-lU8p7OE9D5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htbhG_H5I53Z"
      },
      "source": [
        "### 3.2.2 Add a New Learnable FC Layer to ResNet18\n",
        "\n",
        "If you look at the summary of ResNet18 shown above, you will see that the last layer is:\n",
        "\n",
        "  `(fc): Linear(in_features=512, out_features=1000, bias=True)`\n",
        "\n",
        "In our case, we should just replace this with a new FC layer (its dimensions should be straight-forward to figure out)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NewResNet18.fc = None\n",
        "###########################################################\n",
        "# @TODO: Create a new layer and save it into              #\n",
        "# NewResNet18.fc. This new layer will map the activations #\n",
        "# of the previous layer to the outputs for the CIFAR10    #\n",
        "# classes.                                                #\n",
        "###########################################################\n",
        "\n",
        "\n",
        "###########################################################\n",
        "#                         END OF YOUR CODE                #\n",
        "###########################################################"
      ],
      "metadata": {
        "id": "yxsng68c9KMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQic000dKCBi"
      },
      "source": [
        "### 3.2.3 Visualize the Model\n",
        "\n",
        "Now, let us see whether the new fc layer is correct for CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(NewResNet18.fc)"
      ],
      "metadata": {
        "id": "Caug6kMO9Owh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VqkhyAf1s4"
      },
      "source": [
        "## 3.3 Finetune ResNet18\n",
        "\n",
        "While finetuning ResNet18, we will just update the last layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Xwis1-J26R"
      },
      "source": [
        "### 3.3.1 Training Method\n",
        "\n",
        "This is the same training method from Task 2."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, epochs, dataloader, verbose=True):\n",
        "  \"\"\"\n",
        "    Define the trainer function. We can use this for training any model.\n",
        "    The parameter names are self-explanatory.\n",
        "\n",
        "    Returns: the loss history.\n",
        "  \"\"\"\n",
        "  loss_history = []\n",
        "  for epoch in range(epochs):\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "      # Our batch:\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # zero the gradients as PyTorch accumulates them\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Obtain the scores\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = criterion(outputs.to(device), labels)\n",
        "\n",
        "      # Backpropagate\n",
        "      loss.backward()\n",
        "\n",
        "      # Update the weights\n",
        "      optimizer.step()\n",
        "\n",
        "      loss_history.append(loss.item())\n",
        "\n",
        "    if verbose: print(f'Epoch {epoch} / {epochs}: avg. loss of last 5 iterations {np.sum(loss_history[:-6:-1])/5}')\n",
        "\n",
        "  return loss_history"
      ],
      "metadata": {
        "id": "hdZj92vK9UR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15VCbg0lKPIz"
      },
      "source": [
        "### 3.3.2 Finetune the Adapted ResNet18 on CIFAR10\n",
        "\n",
        "We will only provide the learnable parameters to the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# For reproducibility, let us recreate the FC layer here with a fixed seed:\n",
        "torch.manual_seed(403)\n",
        "random.seed(403)\n",
        "np.random.seed(403)\n",
        "\n",
        "NewResNet18.fc = None\n",
        "###########################################################\n",
        "# @TODO: Repeat what you did in 3.2.2 here                  #\n",
        "###########################################################\n",
        "\n",
        "\n",
        "###########################################################\n",
        "#                         END OF YOUR CODE                #\n",
        "###########################################################\n",
        "\n",
        "def get_learnable_parameters(model):\n",
        "    params_to_update = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "    return params_to_update\n",
        "\n",
        "parameters_to_update = get_learnable_parameters(NewResNet18)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(parameters_to_update, lr=0.0001, momentum=0.95)\n",
        "\n",
        "NewResNet18 = NewResNet18.to(device)\n",
        "epochs = 2\n",
        "loss_history = train(NewResNet18, criterion, optimizer, epochs, trainloader)"
      ],
      "metadata": {
        "id": "30fapGbT9XYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SUT6gj9KenX"
      },
      "source": [
        "### 3.3.3 The Loss Curve\n",
        "\n",
        "You will see that the loss curve is very noisy, which suggests that we should finetune our hyper-parameters. Though, we will see that we get already reasonably well performance on test data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_history)\n",
        "plt.xlabel('Iteration number')\n",
        "plt.ylabel('Loss value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bikuvprP9bVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cBp7Xu_Kkhp"
      },
      "source": [
        "### 3.3.4 Quantitative Results\n",
        "\n",
        "We can analyze the accuracy of the predictions as follows. You should see around 69\\% accuracies. We can finetune the hyperparameters to obtain better results.\n",
        "\n",
        "*Disclaimer: This code piece is taken from PyTorch examples.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "NewResNet18 = NewResNet18.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = NewResNet18(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "id": "kXUwF4ff9e9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69QV-5JKVHVl"
      },
      "source": [
        "### 3.3.5 Visual Results\n",
        "\n",
        "We see that with just two epochs of training a single FC layer, we can get decent results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "# Get scores for classes on the batch\n",
        "with torch.no_grad():\n",
        "    output = NewResNet18(images)\n",
        "\n",
        "# Convert them to probabilities (shape: batch_size x 1000)\n",
        "probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "\n",
        "# Show results on a 2x2 grid\n",
        "S=2\n",
        "for i in range(S):\n",
        "  for j in range(S):\n",
        "    X = images[i*S+j]\n",
        "    X = np.transpose((X.to(\"cpu\").numpy()/2+0.5), (1, 2, 0))\n",
        "    top1_prob, top1_catid = torch.topk(probabilities[i*S+j], 1)\n",
        "    title = \"{} p:{:1.2f}\".format(CIFAR10_classes[top1_catid], top1_prob.item())\n",
        "\n",
        "    plt.subplot(S, S, i*S+j+1)\n",
        "    plt.imshow(X)\n",
        "    plt.axis('off')\n",
        "    plt.title(title)\n",
        "    plt.subplots_adjust(hspace = 0.5)\n"
      ],
      "metadata": {
        "id": "O1gI76tb9iUV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}