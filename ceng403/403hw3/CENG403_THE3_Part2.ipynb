{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CENG403 - Spring 2024 - THE3\n",
        "\n",
        "# Task 2: CNN with PyTorch\n",
        "In this task, you will implement a convolutional neural network (CNN) with PyTorch.\n"
      ],
      "metadata": {
        "id": "YwiHTe0h1VyJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRaKrjO5JSu-"
      },
      "source": [
        "## 2.1 Import the Modules\n",
        "\n",
        "Let us start with importing some libraries that we will use throughout the task."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch libraries:\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# install and import the torchinfo library\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "N6JE4vyN1m7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BXVQOGRI4Sc"
      },
      "source": [
        "## 2.2 Enable GPU\n",
        "\n",
        "First, under \"Edit -> Notebook Settings -> Hardware accelerator\", select a GPU. With the following, we will inform PyTorch that we want to use the GPU."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"Cuda (GPU support) is available and enabled!\")\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  print(\"Cuda (GPU support) is not available :(\")\n",
        "  device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "gwyCwPFm1nUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMmi17e-JX7o"
      },
      "source": [
        "## 2.3 The Dataset\n",
        "\n",
        "We will use torchvision.datasets to download the CIFAR10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "uBE2rRlo2jT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i9tug4jGGg4"
      },
      "source": [
        "### 2.3.1 Visualize Samples"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "S = 4\n",
        "\n",
        "for i in range(S):\n",
        "  for j in range(S):\n",
        "    images, labels = next(dataiter)\n",
        "    X = np.transpose(images[0].numpy()/2+0.5, (1, 2, 0))\n",
        "    y = labels[0]\n",
        "\n",
        "    plt.subplot(S, S, i*S+j+1)\n",
        "    plt.imshow(X)\n",
        "    plt.axis('off')\n",
        "    plt.title(classes[y])\n",
        "    plt.subplots_adjust(hspace = 0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QPRHXL192k1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUmdAA1QJvRx"
      },
      "source": [
        "## 2.4 Define and Train a Small CNN Model\n",
        "\n",
        "Now, all the pieces are ready and we can define a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJq7aT_wh9SK"
      },
      "source": [
        "### 2.4.1 Model Definition\n",
        "\n",
        "Create a three-layer CNN with the following layers:\n",
        "\n",
        "| Layer Name | Input HxW | Filter size | Stride | Pad | # of in channels | Out HxW | # of out channels |\n",
        "| ----| -----| ----| ---| ---| ----| -----|---------- |\n",
        "| Conv1   | 32x32 | ? | ? | ? | 3  | 28x28 | 16 |\n",
        "| Conv2   | 28x28 | ? | ? | ? | 16 | 26x26 | 32 |\n",
        "| Maxpool | 26x26 | 4 | 2 | 0 | 32 | 12x12 | 32 |\n",
        "| Conv3   | 12x12 | ? | ? | ? | 32 | 10x10 | 32 |\n",
        "\n",
        "and the fully-connected layers:\n",
        "\n",
        "| Layer Name | Input Size | Output size |\n",
        "| ----| -----| ----|\n",
        "| FC1 | 3200 | 1500 |\n",
        "| FC2 | 1500 | 10 |\n",
        "\n",
        "You should choose suitable values for variables marked with `?' in the table and make sure that receptive fields can be properly placed in all layers.\n",
        "\n",
        "While creating your model, pay attention to the following aspects:\n",
        "* Each Conv layer and FC layer will be followed by ReLU, except for the last one.\n",
        "* You should keep all other parameters (dilation, bias, group-mode, ..) as their default values in Pytorch.\n",
        "\n",
        "You will need to read the following pages from Pytorch regarding the layers that you will use:\n",
        "* [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
        "* [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html?highlight=maxpool#torch.nn.MaxPool2d)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SmallCNN, self).__init__()\n",
        "        torch.manual_seed(403)\n",
        "        random.seed(403)\n",
        "        np.random.seed(403)\n",
        "        self.conv1 = None\n",
        "        self.conv2 = None\n",
        "        self.conv3 = None\n",
        "        self.maxpool = None\n",
        "        self.fc1 = None\n",
        "        self.fc2 = None\n",
        "        ###########################################################\n",
        "        # @TODO: Create the convolutional and FC layers as        #\n",
        "        #  described above.                                       #\n",
        "        ###########################################################\n",
        "\n",
        "        ###########################################################\n",
        "        #                         END OF YOUR CODE                #\n",
        "        ###########################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "      ###########################################################\n",
        "      # @TODO: Feedforward x through the layers. Note that x    #\n",
        "      # needs to be reshaped to (batchsize, 3200) before        #\n",
        "      # the FC layers.                                          #\n",
        "      ###########################################################\n",
        "\n",
        "      ###########################################################\n",
        "      #                         END OF YOUR CODE                #\n",
        "      ###########################################################\n",
        "      return x"
      ],
      "metadata": {
        "id": "NkzMEoqq28Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvpiVF5uiBE9"
      },
      "source": [
        "### 2.4.2 Trainer for the Model\n",
        "\n",
        "Let us define our training function, which will use the cuda device for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Flgr2C6Xb2s"
      },
      "source": [
        "def train(model, criterion, optimizer, epochs, dataloader, verbose=True):\n",
        "  \"\"\"\n",
        "    Define the trainer function. We can use this for training any model.\n",
        "    The parameter names are self-explanatory.\n",
        "\n",
        "    Returns: the loss history.\n",
        "  \"\"\"\n",
        "  loss_history = []\n",
        "  for epoch in range(epochs):\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "      # Our batch:\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # zero the gradients as PyTorch accumulates them\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Obtain the scores\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = criterion(outputs.to(device), labels)\n",
        "\n",
        "      # Backpropagate\n",
        "      loss.backward()\n",
        "\n",
        "      # Update the weights\n",
        "      optimizer.step()\n",
        "\n",
        "      loss_history.append(loss.item())\n",
        "\n",
        "    if verbose: print(f'Epoch {epoch} / {epochs}: avg. loss of last 5 iterations {np.sum(loss_history[:-6:-1])/5}')\n",
        "\n",
        "  return loss_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_QLjjxUIkKs"
      },
      "source": [
        "### 2.4.3 Create and visualize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIHLBpztIeWa"
      },
      "source": [
        "model = SmallCNN()\n",
        "\n",
        "summary(model, input_size=(batch_size, 3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r8pT7Y9FmDH"
      },
      "source": [
        "### 2.4.4 Train the Small Model\n",
        "\n",
        "We will create an instance of our model and \"define\" which loss function we want to use. We will also state our choice for the optimizer here.\n",
        "\n",
        "For more information, check the PyTorch docs: [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) and [SGD](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gg_Xp3vrg42"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "model = model.to(device)\n",
        "epochs = 10\n",
        "loss_history = train(model, criterion, optimizer, epochs, trainloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DILBn6y92Ceg"
      },
      "source": [
        "### 2.4.5 The Loss Curve\n",
        "\n",
        "Let us visualize the loss curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNZBSrzXiVVe"
      },
      "source": [
        "plt.plot(loss_history)\n",
        "plt.xlabel('Iteration number')\n",
        "plt.ylabel('Loss value')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPMf0jfF2zo6"
      },
      "source": [
        "### 2.4.6 Quantitative Analysis\n",
        "\n",
        "We can analyze the accuracy of the predictions as follows. You should see around 54\\% accuracies. We can finetune the hyperparameters to obtain better results. But we will skip that and go for a bigger model.\n",
        "\n",
        "*Disclaimer: This code piece is taken from PyTorch examples.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model = model.to(\"cpu\")\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "id": "VNh6v-lN3uvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4AJXtea2427"
      },
      "source": [
        "## 2.5 Your CNN\n",
        "\n",
        "Now, create your own CNN. It should have at least 5 convolutional layers. Other than that, there is no restriction on what you can use in your CNN or how you can structure it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr7NvUrWW9ax"
      },
      "source": [
        "### 2.5.1 Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class YourCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(YourCNN, self).__init__()\n",
        "        torch.manual_seed(403)\n",
        "        random.seed(403)\n",
        "        np.random.seed(403)\n",
        "        ###########################################################\n",
        "        # @TODO: Create your layers here.                         #\n",
        "        ###########################################################\n",
        "        ###########################################################\n",
        "        #                         END OF YOUR CODE                #\n",
        "        ###########################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "      ###########################################################\n",
        "      # @TODO: Feedforward x through the layers.                #\n",
        "      ###########################################################\n",
        "      ###########################################################\n",
        "      #                         END OF YOUR CODE                #\n",
        "      ###########################################################\n",
        "      return x"
      ],
      "metadata": {
        "id": "cmCLc6D84Ewm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjayBqpCXBJG"
      },
      "source": [
        "### 2.5.2 Create and visuale your model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YourCNN()\n",
        "\n",
        "summary(model, input_size=(batch_size, 3, 32, 32))"
      ],
      "metadata": {
        "id": "qXIdA3ra4FUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQw2uB8kXFu-"
      },
      "source": [
        "### 2.5.3 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "model = model.to(device)\n",
        "epochs = 10\n",
        "loss_history = train(model, criterion, optimizer, epochs, trainloader)"
      ],
      "metadata": {
        "id": "cL2yV7Ru4MI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KD1t5l6WpzE"
      },
      "source": [
        "### 2.5.4 Loss Curve\n",
        "\n",
        "Let us visualize the loss curve."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_history)\n",
        "plt.xlabel('Iteration number')\n",
        "plt.ylabel('Loss value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qOuvgOGv4OLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRPl6GSAW1mz"
      },
      "source": [
        "### 2.5.5 Quantitative Analysis\n",
        "\n",
        "Analyze your model quantitatively.\n",
        "\n",
        "*Disclaimer: This code piece is taken from PyTorch examples.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model = model.to(\"cpu\")\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "id": "Zx1Kh1pz4XT5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}